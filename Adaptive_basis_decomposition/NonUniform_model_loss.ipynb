{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "\n",
    "# from google.colab import drive\n",
    "# from tqdm import test\n",
    "\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels,  kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.double_conv(x)\n",
    "        down_sampled = self.maxpool(features)\n",
    "        return features, down_sampled\n",
    "\n",
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, add_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Conv2d(add_channels + out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2=None):\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.double_conv(x1)\n",
    "\n",
    "        if x2 is not None:\n",
    "          \n",
    "            diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "            diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "            x = torch.cat([x2, x1], dim=1)\n",
    "        else:\n",
    "            x = x1\n",
    "\n",
    "        feat = self.feat(x)\n",
    "        return feat\n",
    "\n",
    "class PooledSkip(nn.Module):\n",
    "    def __init__(self, output_spatial_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_spatial_size = output_spatial_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        global_avg_pooling = x.mean((2,3), keepdim=True) #self.gap(x)\n",
    "        #print('gap shape:' , global_avg_pooling.shape)\n",
    "        return global_avg_pooling.repeat(1, 1, self.output_spatial_size,self.output_spatial_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(loader, clf, criterion, opt):\n",
    "    clf.train(True)\n",
    "\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    n_observations = 0\n",
    "    for images, labels in loader:\n",
    "      \n",
    "      inputs, labels = images.cuda(), labels.cuda()\n",
    "      opt.zero_grad()\n",
    "\n",
    "      outputs = clf(inputs)\n",
    "      loss_i = criterion(outputs, labels)\n",
    "      loss_i.backward()\n",
    "      opt.step()\n",
    "\n",
    "      loss += loss_i.item()\n",
    "      accuracy += torch.sum(labels == outputs.argmax(dim=-1))\n",
    "      n_observations += labels.shape[0]\n",
    "\n",
    "    loss /= len(loader)\n",
    "    accuracy /= n_observations\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "def epoch_test(loader, clf, criterion):\n",
    "    clf.eval()\n",
    "\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    n_observations = 0\n",
    "    for images, labels in loader:\n",
    "      \n",
    "      inputs, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "      outputs = clf(inputs)\n",
    "      loss_i = criterion(outputs, labels)\n",
    "\n",
    "      loss += loss_i.item()\n",
    "      accuracy += torch.sum(labels == outputs.argmax(dim=-1))\n",
    "      n_observations += labels.shape[0]\n",
    "\n",
    "    loss /= len(loader)\n",
    "    accuracy /= n_observations\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "def train(train_loader, test_loader, clf, criterion, opt, n_epochs=50):\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss, train_acc = epoch_train(train_loader, clf, criterion, opt)\n",
    "        test_loss, test_acc = epoch_test(test_loader, clf, criterion)\n",
    "\n",
    "        print(f'[Epoch {epoch + 1}] train loss: {train_loss:.3f}; train acc: {train_acc:.2f}; ' + \n",
    "              f'test loss: {test_loss:.3f}; test acc: {test_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeblurNN(nn.Module):\n",
    "    def __init__(self, K=9, blur_kernel_size=33, bilinear=False,\n",
    "                 no_softmax=False):\n",
    "        super(DeblurNN, self).__init__()\n",
    "\n",
    "        self.no_softmax = no_softmax\n",
    "        if no_softmax:\n",
    "            print('Softmax is not being used')\n",
    "\n",
    "        self.inc_rgb = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.inc_gray = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        self.blur_kernel_size = blur_kernel_size\n",
    "        self.K=K\n",
    "\n",
    "        self.down1 = DownSampleBlock(64, 64)\n",
    "        self.down2 = DownSampleBlock(64, 128)\n",
    "        self.down3 = DownSampleBlock(128, 256)\n",
    "        self.down4 = DownSampleBlock(256, 512)\n",
    "        self.down5 = DownSampleBlock(512, 1024)\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        self.up1 = UpSampleBlock(1024,1024, 512, bilinear)\n",
    "        self.up2 = UpSampleBlock(512,512, 256, bilinear)\n",
    "        self.up3 = UpSampleBlock(256,256, 128, bilinear)\n",
    "        self.up4 = UpSampleBlock(128,128, 64, bilinear)\n",
    "        self.up5 = UpSampleBlock(64,64, 64, bilinear)\n",
    "\n",
    "        self.masks_end = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, K, kernel_size=3, padding=1),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        self.feat5_gap = PooledSkip(2)\n",
    "        self.feat4_gap = PooledSkip(4)  \n",
    "        self.feat3_gap = PooledSkip(8)  \n",
    "        self.feat2_gap = PooledSkip(16)  \n",
    "        self.feat1_gap = PooledSkip(32) \n",
    "\n",
    "        self.kernel_up1 = UpSampleBlock(1024,1024, 512, bilinear)\n",
    "        self.kernel_up2 = UpSampleBlock(512,512, 256, bilinear)\n",
    "        self.kernel_up3 = UpSampleBlock(256,256, 256, bilinear)\n",
    "        self.kernel_up4 = UpSampleBlock(256,128, 128, bilinear)\n",
    "        self.kernel_up5 = UpSampleBlock(128,64, 64, bilinear)\n",
    "        if self.blur_kernel_size>33:\n",
    "            self.kernel_up6 = UpSampleBlock(64, 0, 64, bilinear)\n",
    "\n",
    "        self.kernels_end = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=2, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(64, K, kernel_size=3, padding=1)\n",
    "            #nn.Conv2d(128, K*self.blur_kernel_size*self.blur_kernel_size, kernel_size=8),\n",
    "        )\n",
    "        self.kernel_softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Encoder\n",
    "        if x.shape[1]==3:\n",
    "            x1 = self.inc_rgb(x)\n",
    "        else:\n",
    "            x1 = self.inc_gray(x)\n",
    "        x1_feat, x2 = self.down1(x1)\n",
    "        x2_feat, x3 = self.down2(x2)\n",
    "        x3_feat, x4 = self.down3(x3)\n",
    "        x4_feat, x5 = self.down4(x4)\n",
    "        x5_feat, x6 = self.down5(x5)\n",
    "        x6_feat = self.feat(x6)\n",
    "\n",
    "        #k = self.kernel_network(x3)\n",
    "        feat6_gap = x6_feat.mean((2,3), keepdim=True) #self.feat6_gap(x6_feat)\n",
    "        #print('x6_feat: ', x6_feat.shape,'feat6_gap: ' , feat6_gap.shape)\n",
    "        feat5_gap = self.feat5_gap(x5_feat)\n",
    "        #print('x5_feat: ', x5_feat.shape,'feat5_gap: ' , feat5_gap.shape)\n",
    "        feat4_gap = self.feat4_gap(x4_feat)\n",
    "        #print('x4_feat: ', x4_feat.shape,'feat4_gap: ' , feat4_gap.shape)\n",
    "        feat3_gap = self.feat3_gap(x3_feat)\n",
    "        #print('x3_feat: ', x3_feat.shape,'feat3_gap: ' , feat3_gap.shape)\n",
    "        feat2_gap = self.feat2_gap(x2_feat)\n",
    "        #print('x2_feat: ', x2_feat.shape,'feat2_gap: ' , feat2_gap.shape)\n",
    "        feat1_gap = self.feat1_gap(x1_feat)\n",
    "        #print(feat5_gap.shape, feat4_gap.shape)\n",
    "        k1 = self.kernel_up1(feat6_gap, feat5_gap)\n",
    "        #print('k1 shape', k1.shape)\n",
    "        k2 = self.kernel_up2(k1, feat4_gap)\n",
    "        #print('k2 shape', k2.shape)\n",
    "        k3 = self.kernel_up3(k2, feat3_gap)\n",
    "        #print('k3 shape', k3.shape)\n",
    "        k4 = self.kernel_up4(k3, feat2_gap)\n",
    "        #print('k4 shape', k4.shape)\n",
    "        k5 = self.kernel_up5(k4, feat1_gap)\n",
    "\n",
    "        if self.blur_kernel_size==65:\n",
    "            k6 = self.kernel_up6(k5)\n",
    "            k = self.kernels_end(k6)\n",
    "        else:\n",
    "            k = self.kernels_end(k5)\n",
    "        N, F, H, W = k.shape  # H and W should be one\n",
    "        k = k.view(N, self.K, self.blur_kernel_size * self.blur_kernel_size)\n",
    "\n",
    "        if self.no_softmax:\n",
    "            k = F.leaky_relu(k)\n",
    "            #suma = k5.sum(2, keepdim=True)\n",
    "            #k = k5 / suma\n",
    "        else:\n",
    "            k = self.kernel_softmax(k)\n",
    "\n",
    "        k = k.view(N, self.K, self.blur_kernel_size, self.blur_kernel_size)\n",
    "\n",
    "        #Decoder\n",
    "        x7 = self.up1(x6_feat, x5_feat)\n",
    "        x8 = self.up2(x7, x4_feat)\n",
    "        x9 = self.up3(x8, x3_feat)\n",
    "        x10 = self.up4(x9, x2_feat)\n",
    "        x11 = self.up5(x10, x1_feat)\n",
    "        logits = self.masks_end(x11)\n",
    "\n",
    "        return  k, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def loss(kernel, coeff, k_reference, img_input, img_ref, norma):\n",
    "    #Constants\n",
    "    n_i = (0.1**0.5)*torch.rand(1).to(device) #Noise\n",
    "    gamma = 2.2\n",
    "    a = 50\n",
    "    K = 33\n",
    "    K_half = K // 2\n",
    "    \n",
    "    #Variables preparations\n",
    "\n",
    "    v_i_gt = img_input #Initially blured image\n",
    "    v_i = torch.zeros((1, 3, img_ref.shape[2], img_ref.shape[3])).to(device) #Reblured image\n",
    "\n",
    "    #Sharp image\n",
    "    u_i = torch.zeros((img_ref.shape[0], img_ref.shape[1], \n",
    "                       img_ref.shape[2] + K - 1, img_ref.shape[3] + K - 1)).to(device)\n",
    "    u_i[:, :, K_half : u_i.shape[2] - K_half, K_half : u_i.shape[3] - K_half] = img_ref[:, :, :, :].to(device)\n",
    "    \n",
    "    #Losses\n",
    "    Loss_reblur = torch.zeros((1, 3, img_ref.shape[2], img_ref.shape[3])).to(device)\n",
    "    Loss_kernel = torch.zeros((1, 3, img_ref.shape[2], img_ref.shape[3])).to(device)\n",
    "\n",
    "    for i in range(K_half, img_ref.shape[2] - K_half):\n",
    "        for j in range(K_half, img_ref.shape[3] - K_half):\n",
    "            print(i, j)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            i_v = i - K_half\n",
    "            j_v = j - K_half\n",
    "            \n",
    "            weight = 1 #1 pixel per kernel\n",
    "            #weight = 1 / number_of_pixels_per_kernel\n",
    "\n",
    "            #Calculate Reblur Kernel for pixel ij\n",
    "            Ker = torch.sum(kernel * coeff[:, :, i_v, j_v].unsqueeze(-1).unsqueeze(-1), dim = 1)\n",
    "            Kerij = Ker.repeat(3, 3, 1, 1)\n",
    "            # print(Ker.shape)\n",
    "\n",
    "            #Calculate Reblur Loss\n",
    "            R = v_i_gt[:, :, i_v, j_v] - 1 / a * torch.log(1 + torch.exp(a * (v_i_gt[:, :, i_v, j_v] - 1)))\n",
    "            # print(R.shape)\n",
    "            u_nn = u_i[:, :, i - K_half : i + K_half + 1, j - K_half : j + K_half + 1]\n",
    "            v_i[:, :, i_v, j_v] = R * (F.conv2d(u_nn, Kerij)[0, :, 0, 0] + n_i) ** (1 / gamma)\n",
    "            # print(v_i[:, :, i_v, j_v])\n",
    "\n",
    "            Loss_reblur[:, :, i_v, j_v] = weight * (v_i[:, :, i_v, j_v] - v_i_gt[:, :, i_v, j_v]) ** 2\n",
    "            print(Loss_reblur[:, :, i_v, j_v])\n",
    "            ##Calculate Kernel Loss\n",
    "            Ker = Ker.unsqueeze(0)\n",
    "\n",
    "            Loss_kernel[:, :, i_v, j_v] = weight * torch.linalg.matrix_norm(Ker - k_reference, ord = norma)\n",
    "            print(Loss_kernel[:, :, i_v, j_v])\n",
    "\n",
    "    return torch.sum(Loss_reblur), torch.sum(Loss_kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1442]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(1, 1, 2, 3)\n",
    "print(a[:, :, 1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
